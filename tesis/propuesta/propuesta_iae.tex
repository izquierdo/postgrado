\documentclass{article}

\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{txfonts}
\usepackage[boxed]{algorithm2e}
\usepackage{amssymb}
\usepackage[pdftex]{graphicx}
\usepackage[utf8x]{inputenc}
\usepackage{enumerate}
\DeclareGraphicsExtensions{.jpg, .png, .mps, .bmp, .pdf}
\usepackage{epsfig}
\usepackage{subfigure}
\newtheorem{Definition}{Definition} 
\newtheorem{Example}{Example} 
\newtheorem{Theorem}{Theorem} 
\newtheorem{Proof}{Proof} 
\newcommand{\denselist}{\topsep 0pt \itemsep -4pt}
\newcommand{\tup}[1]{\langle #1 \rangle}
\newcommand{\vvec}[1]{\mathbf{#1}}
\newcommand{\join}{\bowtie}
\newcommand{\R}{\mathcal{R}}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\body}{{body}}
\newcommand{\head}{{head}}
\newcommand{\qrule}{:\!\!-}
\newcommand{\arc}{\text{arc}}
\newcommand{\Theory}[1]{T(#1)}
\newcommand{\mcdsat}{\textsc{McdSat}}
\newcommand{\minicon}{{MiniCon}}
\newcommand{\Omit}[1]{}
\newcommand{\citeX}[1]{\citeauthor{#1}~\citeyear{#1}}

\newcommand{\comment}[1]{}

\newcommand{\mcdsatc}{{\it MCDSat}$^c$}

\begin{document}

\comment{
\allowdisplaybreaks
\title{Selección de Servicios Web De Máxima Utilidad Usando Circuitos}
\author{Daniel Izquierdo}

{Universidad Sim\'on Bol\'{\i}var\\
                Caracas, Venezuela\\
                idaniel@ldc.usb.ve} \maketitle

\section{Related Work}
In this section we summarize existing approaches that provide solutions to the problems of service selection, knowledge representation and query rewriting. 

\begin{description}
\item[Service Selection Solutions] \mbox{}\\
The problem of selecting the services that implement an abstract workflow and best meet the QoS-based criteria  is known as the QoS-aware service selection or composition problem, which has been shown to be NP-hard~\cite{Hiroshi2008}. This problem is a combinatorial optimization problem and several heuristics have been proposed to find a relatively good solution in a reasonably short period of time.  A  distance metric-based heuristic  to drive a backward search algorithm  is proposed~\cite{rahmani08}; this metric induces an order of the services in a way that sink nodes are unlikely to be visited. In ~\cite{berardi05,berardi08,berardi06}, services and workflows are described in terms of deterministic finite state machines that are encoded as a Description Logic theory whose models correspond to solutions of the problem;  although reasoning methods for Description Logics formalisms could be exploited, scalability or performance of the proposed solution has not been reported.  ~\cite{myoung08} propose a constraint-based approach that encodes the non-functional permissible values as a set of constraints whose violation needs to be minimized; to traverse the space of possibly optimal solutions, a hybrid algorithm that combines the tabu search and simulating annealing meta-heuristics is implemented; experimental results show that the proposed solution is able to scale up to a large number of services and abstract processes.  In ~\cite{cardellini07} the QoS-aware service composition problem is encoded as a Linear Programming problem providing a scalable solution to the problem.  In ~\cite{Hiroshi2008}  this problem  is defined as a multi-objective optimization problem where the different QoS parameters are considered equally important and there is not an aggregated function to combine all of them; a genetic-based algorithm is proposed to identify a set of non-dominated service compositions that best meet all the QoS parameters.  ~\cite{alrifaiR09} propose a two-fold solution that uses a hybrid integer programming algorithm to find the decomposition of global QoS into local constraint, and then,  selects the services that best meet the local constraints.   
Recently,  two new planning-based approaches have been proposed~\cite{kuterG09,sohrabiM09}.  ~\cite{kuterG09} extend the SHOP2 planning algorithm to select the trustworthy composition of services that implement a given OWL-S process model, while ~\cite{sohrabiM09}  propose a HTN planning-based solution where user preference metrics and domain regulations are used to guide the planner into the space of relevant compositions. Finally, ~\cite{lecue09} proposes a genetic-based algorithm to identify the composition of services that best meet the quality criteria for a set of QoS parameters.  

Although these solutions are able to efficiently solve the optimization problem and scale up to a large number of abstract processes, none of them are tailored to semantically describe services in terms of the abstract process, or use these descriptions to identify the services that  implement a given workflow and best meet user non-functional criteria.

  
\item[Knowledge Compilation Languages] \mbox{}\\
Knowledge compilation is the area in AI concerned with the
problem of mapping logical theories into suitable fragments
that make certain desired operations tractable
\cite{cadoli:compilation}. Different compilation languages have been defined, for instance,  
Ordered Binary Decision Diagrams (OBDDs)~\cite{bryant:obdd},  Negation Normal Form (NNF) \cite{barwise:handbook}, and Decomposable Negation Normal Form (DNNF)  \cite{darwiche:dnnf}.
In this work we make use of the properties of the deterministic DNNFs  (d-DNNF) \cite{darwiche:d-dnnfs} to provide an scalable and efficient solution to the service selection problem. 

A Negation Normal Form (NNF) theory is  constructed from literals using only conjunctions
and disjunctions \cite{barwise:handbook}, and it can be represented as a directed acyclic graph
in which the leaves are labeled with literals and the
internal nodes are labeled with $\land$ and $\lor$;
see Fig.~\ref{fig:dnnf} for an example. An NNF is said to be decomposable (DNNF) \cite{darwiche:dnnf}
if for each conjunction $\bigwedge_i\phi_i$, the set of
variables in each conjunct are pairwise disjoint;
i.e,. $Vars(\phi_i)\cap Vars(\phi_j)=\empty$ for $i<j$.
A DNNF supports a number of operations in
polynomial time in the size of its DAG. For example,
we can test whether a DNNF is satisfiable by a single
bottom-up pass over its DAG in linear time. A DNNF is said to be deterministic (d-DNNF) \cite{darwiche:d-dnnfs} if for each disjunction $\bigvee_i\phi_i$, the disjuncts
are pairwise logically contradictory; i.e.,
$\phi_i\Rightarrow\neg\phi_j$ for $i<j$.
The NNF in Fig.~\ref{fig:dnnf}, for example, is decomposable
and deterministic. A d-DNNF supports the model counting and enumeration in polynomial time
in the size of its DAG.  {\it MCDSat}$^c$  exploits the properties of a d-DNNF theory, to efficiently provide a solution to the problem of enumerating the service compositions that correspond to models of the  theory, i.e., the service compositions that implement the abstract  workflow and best meet the utility function. DECIR ALGO SOBRE EL ALGORITMO QUE PRODUCE LOS MEJORES.



\begin{figure}
\centering
%\includegraphics[width=8cm]{odd}
\caption{A decomposable and deterministic NNF.}
\label{fig:dnnf}
\end{figure}


\item[Query Rewriting Solutions] \mbox{}\\
A number of algorithms have been developed to find the rewritings of a given query; the most prominent being the bucket algorithm~\cite{levy:bucket},  the inverse rules algorithm ~\cite{duschka:answer,Qian96}, the minicon algorithm ~\cite{pottinger:minicon}, and the {\it MCDSat} ~\cite{arvelo:aaai06}. Generally, query rewriting algorithms work in two phases: first, they identify the views that rewrite at least one  subgoal of the query; second they combine the selected views to produce a rewriting. The main difference between existing approaches, is the criteria used to choose the relevant views and reduce the space of non-useful rewritings.

The bucket algorithm reduces the number of possibilities just considering each subgoal in the query in isolation, and selecting the views that are able to  produce at least the attributes projected by the query. Since, attributes involved in query joins are not verified, a large number of rewritings comprised of  Cartesian products may  be generated. 	
The Inverse Rules algorithm constructs a set of rules that invert the view definition and establish how to compute tuples for the database relations from tuples of the views. Similarly, to the bucket algorith it can produce a large number non-useful of rewritings. 

The MiniCon algorithm  overcomes the limitations of the previous algorithms by identifying only views that rewrite a set of the query goals and that  can be combined with the rest of the query subgoals. The key idea is to identify the mappings between  the variables in each subgoal of the query to the variables  in one or more subgoals of the views, in a way that, join variables in the query are mapped to join variables in the body of a view or to the distinguished variables of the view. Mappings between variables and subgoals are represented in MiniCon Descriptions (MCD's)\cite{pottinger:minicon}.

Finally,  the
{\it MCDSat} algorithm is able to identify the query rewritings of a query by translating the problem of rewriting
into the problem of enumerating the models of a propositional
theory  $\Theory{\Q}$ whose models are in correspondence
with the rewritings of the query. 
The {\it MCDSat} algorithm exploits the properties of d-DNNFs to efficiently 
compute the MCDs associated with theory $\Theory{\Q}$.
The  {\it MCDSat} algorithm has demonstrated to scale better than the MiniCon
algorithm over a large number of benchmarks often showing performance
improvements of several orders of magnitude. However, the McdSat algorithm was not desgined for rewriting problems involving explicit constants,
nor to compute the best rewritings with respect to a given utility function or cost model, and this paper we propose a new encoding  that overcomes these limitations.


\end{description}

\section{The McdSat$^c$ Architecture}

In order to do so, the theory $\Theory{\Q}$ is transformed into a d-DNNF
theory $\Delta(\Q)$ with a CNF to d-DNNF compiler.
The compiler's algorithm is similar to the DPLL algorithm
for SAT but enhanced with advanced techniques such as clause
learning and caching.
\begin{figure}
\centering
%COMENTADO\includegraphics[width=10cm]{mdcsatC.pdf}
\caption{The McdSat$^c$ Architecture}
\label{fig:dnnf}
\end{figure}



\section{Experimental Results}
We have conducted an empirical analysis  on the benefits of the techniques implemented in the   McdSat$^c$ system.

\begin{description}
\item[Dataset and Query Benchmark:]  we conducted our experiments over a benchmark that includes XX queries and a set of  YY views. Queries and views are starts and chains, and they have between ZZ and fTT constants; queries have QQ sub-subgoals.
\item[Evaluation Metrics:] we report on runtime performance which corresponds to the  {\it user time} produced by the {\it time} command of the Unix operation system. 
\end{description}
 
\begin{figure}
\centering
%COMENTADO\includegraphics[width=8cm]{plot1.pdf}
\caption{Compilation Time Benchmark I}
\label{fig:plot1}
\end{figure}


\section{Formalization of the Service Selection Problem}

We consider databases of the form $D=\tup{P,T}$ where
$P$ is a set of predicates and $T=\{T_p\}_{p\in P}$ is a collection
of tables that represents the predicates in extensional form.
A conjunctive query $Q$ over $P$ is of the form 
\begin{alignat*}{1}
Q(\vvec{x})\ \qrule\ \  p_1(\vvec{x}_1),\, p_1(\vvec{x}_2),\, \ldots,\, p_m(\vvec{x}_m)\,,
\end{alignat*}
where $p_i\in P$, $\vvec{x}$ is a vector of variables, and each
$\vvec{x}_i$ is a vector of variables and constants.
The result of $Q$ over $D$, denoted as $Q(D)$, is the table with
$|\vvec{x}|$ columns that result of the projection of the relational
join $\join\!\!\{T_{p_i}\}_{i=1}^m$ over $\vvec{x}$.
The atoms in the body of $Q$ are called the (sub)goals of $Q$.

A view $V$ over $D$ is a query over $P$. In the context of the service selection problem, 
the database $D$ is an idealized description of 
the output produced abstract workflow  implemented by multiple concrete services described
as views.
Given a database $D$, a query $Q$ and a collection of 
views $E=\tup{\{V_i\}_i,\{E_i\}_i}$, we are required to find
all the tuples in $Q(D)$ obtainable from the views in $E$.
That is, we need to find all the \emph{compositions} of the form
\begin{alignat*}{1}
R(\vvec{x})\ \qrule\ \ V_{i_1}(\vvec{x}_1),\, V_{i_2}(\vvec{x}_2),\, \ldots,\, V_{i_n}(\vvec{x}_n)
\end{alignat*}
such that $R(E) \subseteq Q(D)$.
A service selection problem (SSP) is a tuple $\tup{P,Q,\{V_i\}}$ where $P$
is a set of predicates that represent abstract services, $Q$ is a query over $P$ and $\{V_i\}$ is a collection of views that define the concrete services in terms of  abstract services. We assume \emph{safe} problems in the sense that all 
variables mentioned in the head of the query (resp.\ in the head of each view)
appear in the body of the query (resp.,\ in the body of each view); also the input and output restrictions of the abstract services used in the query are satisfied.
Further, we only deal with SSPs with no arithmetic predicates inside the
query or views.
A composition $C$ is \emph{valid} if for all databases $D=\tup{P,T}$
and extensions $\{E_i\}$, $R(E) \subseteq Q(D)$.
A collection $\R$ of valid compositions is a solution if
for all databases $D=\tup{P,T}$ and extensions $\{E_i\}$, there
is no other $\R'$ such that $\R(E)\subset\R'(E)\subseteq Q(D)$.
We are interested in finding a composition $\R$.

\subsection{Logical Theories}

In \cite{arvelo:aaai06}, we showed that a rewriting
for a query $Q$ with $m$ goals can be obtained by enumerating the
models of a logical theory
$\Delta=\Delta_{rew}\cup\Delta_{mcd}^1\cup\cdots\Delta_{mcd}^m$
where $\Delta_{rew}$ specified how to combine $m$ independent
copies of MCD theories $\Delta_{mcd}$ that cover all goals in $Q$.
Each $\Delta^i_{mcd}$ is a copy of the theory $\Delta_{mcd}$
in which each literal $p$ is tagged as $p^i$.
The theory $\Delta_{mcd}$ consists of different groups of 
clauses that guarantees that its models are in correspondence
with the MCDs, while the theory $\Delta_{rew}$ contains additional
clauses to guarantee a sound and complete composition of the MCDs.
The reader is referred to \cite{arvelo:aaai06} for a comprehensive
description of the propositional theory.

Let us describe the difficulties that arise when constants
are presents in a SSP with the following example:
\begin{alignat*}{1}
Q(x,z)\ &\qrule\ \ p_1(x,y),\, p_2(y,z)\,, \\
V_1(x_1)\ &\qrule\ \ p_1(x_1,A)\,, \\
V_2(x_2)\ &\qrule\ \ p_2(B,x_2)\,, \\
V_3(x_3,y_3)\ &\qrule\ \ p_2(x_3,y_3)
%V_4(x_4,y_4)\ &\qrule\ \ p_1(x_1,A),\, p_2(B,y_4)\,,
\end{alignat*}
where $Q$ is the query and $\{V_1,V_2,V_3\}$ are the 
views. In this case, the only rewriting is 
$R(x,z)\qrule V_1(x),V_3(A,z)$ because the candidate 
$R(x,z)\qrule V_1(x),V_2(z)$ is not valid as it maps
$y$ into constants $A$ and $B$ that denote different
objects.

The main problem when handling constants is to
be sure that different constants are not mapped into
each other either directly or indirectly (via transitivity).

\subsection{Utility Functions}

We assume a simple additive utility function in which each view
$V_i$ is associated with a utility measure $c(V_i)$, and the overall utility value of
a composition is the sum of the utility values for the views in it.
An optimal or best service composition is one with maximum utility value,
and the optimal utility value of a SSP is the utility value of a best
service composition. A SSP has always a well-defined optimal
utility value (if there are no compositions, its utility is $0$),
but it may have multiple best service compositions.
The service composition problem with utility consists in finding
all the compositions of maximum utility value.

%The cost model is simple yet expressive; e.g., if all
%costs are unit, then best rewritings are those with
%minimum number of views, yet in cases where views
%represent different sources, it is natural
%to associate them with different costs.


\subsection{Extended Theories}

The theory $\Delta_{mcd}$ makes use of propositions $t_{x,y}$
to denote that the variable/constant $x$ in the query is mapped
into the variable/constant $y$ in the view, and propositions $v_i$
to indicate that the MCD uses view $V_i$.
We obtain a sound and complete theory for SSPs with constants if
$\Delta_{mcd}$ is extended with the clauses:

\begin{enumerate}[C1.]\denselist
\item (Inconsistent-1): $t_{x,A} \Rightarrow \neg t_{x,B}$,
\item (Inconsistent-2): $t_{A,x} \Rightarrow \neg t_{B,x}$,
\item (Inconsistent-3): $\neg t_{A,B}$,
\item (Transitivity-1): $v_i\land t_{A,y}\land t_{x,y}\land t_{x,z}\Rightarrow t_{A,z}$,
\item (Transitivity-2): $v_i\land t_{y,A}\land t_{y,x}\land t_{z,x}\Rightarrow t_{z,A}$.
\end{enumerate}
Clauses C1--C3 prune candidate service compositions in which one constant
is directly mapped into a different one, and the last two implement
a restricted propagation of transitivity.
Similarly, $\Delta_{rew}$ must be extended with the clauses:
\begin{enumerate}[C1.]\denselist
\item[C6.] (Inconsistent-4): $t^i_{x,A} \Rightarrow \neg t^j_{x,B}$.
\end{enumerate}
~\cite{RajaramanSU95} showed that for queries without negation or arithmetic comparisons,  but with constants, and $m$ goals and $q$ variables, it is enough
to consider service compositions of length at most  $m$ plus  $q$ subgoals ~\cite{Ullman00}.

Given a SSP problem $\tup{Q,\{V_i\}}$ possibly with constant 
symbols, we construct logical theories whose models are in
correspondence with the service compositions. These theories are then
compiled into d-DNNF from which all rewritings are extracted
efficiently.
Likewise, best service compositions can be computed by performing model
enumeration twice: the first pass computes the optimal utility function,
and the second filters out suboptimal service compositions.
However, there is a better way, which we will describe in the next section.

\subsection{Maximum-Utility Function}

Darwiche \& Marquis \cite{darwiche:weighted} show how to compute the
rank $r^*(\Delta)$ of a propositional theory $\Delta$
efficiently when $r$ is a literal ranking function and
$\Delta$ is in d-DNNF. A literal ranking function ranks
the models of the theory in terms of the rank of the
literals $l$ that are true in the model, and ranks the
theory as the best rank of its models:
\[ r(\omega) = \sum_{\omega\vDash l} r(l),\quad r^*(\Delta) = \max_{\omega\vDash\Delta} r(\omega)\,. \]
Furthermore, not only $r^*(\Delta)$ can be computed
efficiently from the d-DNNF but also the models that
have such rank.
The procedure for computing the rank converts the d-DNNF
into a circuit in which the literals are replaced by their
ranks, the `or' nodes by `max', and the `and' nodes by `sum'.
The evaluation of the circuit computes the rank of $\Delta$.

We thus obtain a simple method for computing the best
rewritings when the literal ranking function $r_c$ induced
by the cost model $c$ is used; $r_c$ is defined by
$r_c(l)=c(V_i)$ if $l=v^t_i$ for some $t$, and $r_c(l)=0$
otherwise.


\section{Conclusions and Future Work}

compute the best rewritings with respect to an additive
cost model. The cost model is simple yet expressive.
The computation of the best models relies on an arithmetic
circuit that is obtained from the d-DNNF of the propositional
theory.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO
%en la parte del cuadro de Servicios Abstractos y Concretos sale cuadro 1 pero
%el label dice cuadro 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{portada}

\tableofcontents
\newpage

\input{planteamiento}
\input{justificacion}
\input{objetivos}
\input{metodologia}
\input{cronograma}

\addcontentsline{toc}{section}{Referencias} 
\bibliographystyle{abbrv}
\bibliography{ref}

\end{document}
